{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import collections\n",
    "import os\n",
    "\n",
    "path = os.path.abspath(os.getcwd())\n",
    "\n",
    "from prep.derivatives import Preprocess_derivatives\n",
    "\n",
    "from src.supplementary import Define_Derivatives\n",
    "from src.term import normalize_ts, Term\n",
    "from src.trainer import Equation_Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задаём функцию, позволяющую оценивать значений слагаемых уравнения. Это исполнение использует тензоры значений токенов на сетке и через поэлементное умножение тензоры, получает значения слагаемого. Далее, тензор преобразуется в вектор для использования в качестве признака в регрессии. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative_evaluator(term, normalize, eval_params):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Example of the evaluator of token values, appropriate for case of derivatives with pre-calculated values, defined on grid, that take form of tensors\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    term : term.Term, or numpy.ndarray\n",
    "        Object for term of the equation, or its gene, for which the evaluation is done; necessary for the evaluation.\n",
    "    eval_params : dict\n",
    "        Dictionary, containing parameters of the evaluator: in this example, they are \n",
    "        'token matrices' : list/numpy.martix of token (derivatives) values on the grid, 'parameter_indexes' : dictionary of orders of token parameters during the encoding. \n",
    "        In simplest case of only power parameter: 'parameter_indexes':{'power':0}.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    value : numpy.ndarray\n",
    "        Vector of the evaluation of the token values, that shall be used as target, or feature during the LASSO regression.\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    assert 'token_matrices' in eval_params and 'parameter_indexes' in eval_params\n",
    "    if type(term) == Term:\n",
    "        term = term.gene\n",
    "    token_matrices = eval_params['token_matrices']\n",
    "    value = np.copy(token_matrices[0])\n",
    "    for var_idx in np.arange(term.shape[0]):\n",
    "        power = (term[var_idx + eval_params['parameter_indexes']['power']])\n",
    "        value *= eval_params['token_matrices'][int(var_idx / (float(eval_params['parameter_indexes']['power']+1)))] ** int(power)\n",
    "    if normalize:\n",
    "        value = normalize_ts(value)\n",
    "    value = value.reshape(np.prod(value.shape))\n",
    "    return value    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проводим препроцессинг данных и вычисляем значения производных на сетке. Вычисления довольно трудоёмкие => распараллелены, но всё равно могут занять относительно много времени, особенно если считать на ПК. Результаты препроцессинга сохраняем в отдельный файл, чтобы использовать при повторных запусках основного алгоритма. Это экономит время! Для примера используется решение волнового уравнения с белым шумом.\n",
    "<br>\n",
    "В этом примере мы рассмотрим задачу поиска уравнения по синтетическим данным, полученным из решения волнового уравнения: \n",
    "<br>\n",
    "$\\frac{\\partial^2 u}{\\partial t^2} = \\frac{\\partial^2 u}{\\partial x_1^2} + \\frac{\\partial^2 u}{\\partial x_2^2}$,\n",
    "<br>\n",
    "которое отражает эволюцию некоторой величины $u$ в двумерной области. Данные для этого эксперимента можно взять по ссылке: https://drive.google.com/open?id=1joW0zTwkSGLJVpyWxDqoSMzTvRItX24J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing on grid with uniform nodes:\n",
      "Start: 2020-03-03 18:33:33.448178 ; Finish: 2020-03-03 19:19:32.216328\n",
      "Preprocessing runtime: 0:45:58.768150\n"
     ]
    }
   ],
   "source": [
    "op_file_name =  path + '/Preprocessing/Derivatives.npy' # Путь к файлу с исходным полем\n",
    "filename =  path + '/Preprocessing/wave_HP.npy' # Путь к файлу с производными \n",
    "poolsize = 4\n",
    "\n",
    "if 'npy' in filename:\n",
    "    field = np.load(filename)\n",
    "else:\n",
    "    shape = (201, 201, 201)\n",
    "    field = np.loadtxt(filename)\n",
    "    field = field.reshape(shape)\n",
    "field = np.transpose(field, (2, 0, 1))\n",
    "Preprocess_derivatives(field, op_file_name, mp_poolsize=poolsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем значения в узлах сетки для исходной функции и её производных; из них формируем тензор для дальнейшего использования. Также задаём границы области, по которому будет вычисляться уравнение (в примере - обрезаем начало и конец временного ряда + по 15 элементов с каждой границы, чтобы использовать более \"качественные\" производные)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101, 101, 101)\n"
     ]
    }
   ],
   "source": [
    "u_initial = np.load('Preprocessing/Wave_HP/wave_HP.npy')\n",
    "u_initial = np.transpose(u_initial, (2, 0, 1))\n",
    "print(u_initial.shape)\n",
    "\n",
    "derivatives = np.load('Preprocessing/Wave_HP/Derivatives.npy')\n",
    "variables = np.ones((2 + derivatives.shape[1], ) + u_initial.shape)\n",
    "variables[1, :] = u_initial\n",
    "for i_outer in range(0, derivatives.shape[1]):\n",
    "    variables[i_outer+2] = derivatives[:, i_outer].reshape(variables[i_outer+2].shape) \n",
    "    \n",
    "skipped_elems = 15 \n",
    "timeslice = (skipped_elems, -skipped_elems)\n",
    "\n",
    "variables = variables[:, timeslice[0]:timeslice[1], skipped_elems:-skipped_elems, skipped_elems:-skipped_elems]     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем названия токенов для производных, используя функцию **Define_Derivatives()**. Она получает названия токенов в порядке: 1, u, $\\frac{\\partial u}{\\partial x_1}$, $\\frac{\\partial^2 u}{\\partial x_1^2}$, ... , $\\frac{\\partial u}{\\partial x_2}$, $\\frac{\\partial^2 u}{\\partial x_2^2}$, ...\n",
    "<br>\n",
    "Далее зададим параметры для токенов: в этом примере единственным параметром является степень токена, используемого в слагаемом. Например, если 'power' = 2 для токена $\\frac{\\partial u}{\\partial x_1}$, то в слагаемом будет $ (\\frac{\\partial u}{\\partial x_1})^2 $. Также зададим слагаемые, которые будут в каждом уравнении: константу и исходную функцию. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1', 'u', 'du/dx1', 'd^2u/dx1^2', 'du/dx2', 'd^2u/dx2^2', 'du/dx3', 'd^2u/dx3^2')\n"
     ]
    }
   ],
   "source": [
    "token_names = Define_Derivatives(u_initial.ndim, max_order = 2)\n",
    "print(token_names)\n",
    "\n",
    "token_parameters = collections.OrderedDict([('power', (0, 3))])\n",
    "basic_terms = [{'1':{'power':1}},\n",
    "               {'1':{'power':1},  'u':{'power':1}}]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задаём объект для обучения уравнения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trainer = Equation_Trainer(tokens = token_names, token_params = token_parameters, \n",
    "                           evaluator = derivative_evaluator, \n",
    "                           evaluator_params = {'token_matrices':variables, 'parameter_indexes':{'power':0}},\n",
    "                           basic_terms = basic_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как мы не знаем, какой параметр $\\alpha$ - коэффициент регуляризации в LASSO, позволяет получить правильную структуру уравнения, мы проводим запуск по сетке из гиперпараметров модели. Сетка в примере строится только по одному параметру ($\\alpha$), но в общем виде допустимо задавать сетки сразу по нескольким. Для остальные гиперпараметров модели задаём соответствующие значения. В случае, если каждый параметр задаётся одним значением, то их допустимо подавать сразу в метод Train.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trainer.Parameters_grid(('alpha', 'a_proc', 'r_crossover', 'r_param_mutation', 'r_mutation', \n",
    "                         'mut_chance', 'pop_size', 'eq_len', 'max_factors'), \n",
    "                        ((0.01, 0.16, 4), 0.2, 0.6, 0.8, 0.5, 0.8, 20, 6, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запускаем обучение и получаем искомое уравнение в символьной форме"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using parameters from grid\n",
      "Achieved best fitness: 0.0050783488205190215 with alpha = 0.01\n",
      "Discovered equation:\n",
      "- {  d^2u/dx1^2 : {'power': 1.0}} + -0.0001963014668564108 * {  u : {'power': 1.0}} + 1.003430266231036 * {  d^2u/dx2^2 : {'power': 1.0}} + 0.000465301995916656 * {  du/dx1 : {'power': 1.0}} + 1.003430266231037 * {  d^2u/dx3^2 : {'power': 1.0}} = 0\n",
      "Achieved best fitness: 0.004485088661452463 with alpha = 0.06\n",
      "Discovered equation:\n",
      "- {  d^2u/dx1^2 : {'power': 1.0}} + 1.0013594947213769 * {  d^2u/dx3^2 : {'power': 1.0}} + -0.00020581754275531233 * {  u : {'power': 1.0}} + 1.001359494721376 * {  d^2u/dx2^2 : {'power': 1.0}} = 0\n",
      "Achieved best fitness: 0.0038249581919527357 with alpha = 0.10999999999999999\n",
      "Discovered equation:\n",
      "- {  d^2u/dx1^2 : {'power': 1.0}} + 1.0935985825740213 * {  d^2u/dx2^2 : {'power': 1.0}} + 1.0935985825740218 * {  d^2u/dx3^2 : {'power': 1.0}} = 0\n",
      "Achieved best fitness: 0.003611457117138705 with alpha = 0.16\n",
      "Discovered equation:\n",
      "- {  d^2u/dx1^2 : {'power': 1.0}} + 1.0935985825740213 * {  d^2u/dx2^2 : {'power': 1.0}} + 1.0935985825740218 * {  d^2u/dx3^2 : {'power': 1.0}} = 0\n"
     ]
    }
   ],
   "source": [
    "Trainer.Train(epochs = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для основной части исследуемого интервала $\\alpha$ мы получаем структуры уравнения в формате\n",
    "<br>\n",
    "$\\frac{\\partial^2 u}{\\partial t^2} = a_1 \\frac{\\partial^2 u}{\\partial x_1^2} + a_2 \\frac{\\partial^2 u}{\\partial x_2^2}$, \n",
    "<br>\n",
    "где коэффициенты $a_1$ и $a_2$ отличаются от исходных, равных 1, в силу погрешностей, в большей степени связанных с численным решением исходного дифференциального уравнения, а также с погрешностями вычисления производных. \n",
    "<br>\n",
    "При слишком низких значениях $\\alpha$ вектор коэффициентов уравнения недостаточно разрежен, и в уравнении присутствуют лишние слагаемые, хотя и обладают незначительными весами. \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trainer.Parameters_grid(('alpha', 'a_proc', 'r_crossover', 'r_param_mutation', 'r_mutation', \n",
    "                         'mut_chance', 'pop_size', 'eq_len', 'max_factors'), \n",
    "                        ((0.3, 0.4, 2), 0.2, 0.6, 0.8, 0.5, 0.8, 20, 6, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using parameters from grid\n",
      "Achieved best fitness: 0.00227045231823162 with alpha = 0.3\n",
      "Discovered equation:\n",
      "- {  du/dx1 : {'power': 1.0}  d^2u/dx1^2 : {'power': 1.0}} + -0.0004731879609027912 * {  u : {'power': 1.0}} + -0.6650816595841387 * {  d^2u/dx2^2 : {'power': 1.0}} + -0.6650816595841381 * {  d^2u/dx3^2 : {'power': 1.0}} = 0\n",
      "Achieved best fitness: 0.002505082208075159 with alpha = 0.4\n",
      "Discovered equation:\n",
      "- {  d^2u/dx1^2 : {'power': 1.0}} + 1.0935985825740213 * {  d^2u/dx2^2 : {'power': 1.0}} + 1.0935985825740218 * {  d^2u/dx3^2 : {'power': 1.0}} = 0\n"
     ]
    }
   ],
   "source": [
    "Trainer.Train(epochs = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно отметить, что в силу стохастического характера построения уравнений для описания системы и \n",
    "протекающей эволюции, возможны случаи, когда алгоритм не сходится к лучшему решениюб а остается в некотором локальном оптимуме функции приспособленности. Так в случае уравнения для $\\alpha = 0.3$, получается неправильное уравнение.\n",
    "<br>\n",
    "Индикатором этого является сравнительно низкое значение функции приспособленности, отражающей \"качество\" уравнени, которое превышается \"правильными\" структурами даже при больших значениях коэффициента регуляризации. Детали задания фитнес-функции представлены в разделе wiki на github-странице проекта и в соответстующих статьях. \n",
    "<br>\n",
    "Для избежания таких локальных оптимумов, алгоритм рекомендуется запускать несколько раз с одними и теми же данными и выбором значений, соответсвующих максимуму функции приспособленности. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trainer.Parameters_grid(('alpha', 'a_proc', 'r_crossover', 'r_param_mutation', 'r_mutation', \n",
    "                         'mut_chance', 'pop_size', 'eq_len', 'max_factors'), \n",
    "                        ((2, 3, 2), 0.2, 0.6, 0.8, 0.5, 0.8, 20, 6, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using parameters from grid\n",
      "Achieved best fitness: 0.0006686093848979459 with alpha = 2.0\n",
      "Discovered equation:\n",
      "- {  du/dx1 : {'power': 1.0}} = 0\n",
      "Achieved best fitness: 0.0006686093848979459 with alpha = 3.0\n",
      "Discovered equation:\n",
      "- {  du/dx1 : {'power': 1.0}} = 0\n"
     ]
    }
   ],
   "source": [
    "Trainer.Train(epochs = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При дальнейшем увеличении коэффициента регуляризации, уравнение меняет свой вид: теряются значимые слагаемые и принимает вид\n",
    "<br>\n",
    "$\\frac{\\partial^2 u}{\\partial t^2} = 0$:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
